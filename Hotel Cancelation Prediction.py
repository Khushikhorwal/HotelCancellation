# -*- coding: utf-8 -*-
"""ML_PROJECT2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fwq2cEHMQD4fJ0gugw_BL_CEA93YVN_N

## Hotel Cancelation Preidiction

**Importing Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score,precision_score, recall_score, f1_score
from sklearn.metrics import ConfusionMatrixDisplay

!pip install xgboost

"""**Loading Dataset**

[DataSet Link](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand)
"""

df = pd.read_csv('hotel_bookings.csv')
df.head()

df.info()

df.describe()

print(f"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.")

# Check for missing values
print("\nMissing values per column:")
print(df.isnull().sum())

"""# Visualizations(EDA)"""

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='hotel', hue='is_canceled')
plt.title('Cancellations by Hotel Type')
plt.show()

plt.figure(figsize=(6,4))
sns.histplot(data=df, x='lead_time', bins=50, kde=True)
plt.title('Lead Time Distribution')
plt.show()

numeric_df = df.select_dtypes(include=[np.number])
corr = numeric_df.corr()

# Plot heatmap
plt.figure(figsize=(12,8))
sns.heatmap(corr, cmap='coolwarm', annot=True)
plt.title('Correlation Heatmap')
plt.show()

# Target variable: 'is_canceled'
sns.countplot(x='is_canceled', data=df)
plt.title('Booking Cancellation Distribution')
plt.xlabel('Is Canceled')
plt.ylabel('Count')
plt.show()

# Percentage of cancellations
cancellation_rate = df['is_canceled'].value_counts(normalize=True) * 100
print("\nCancellation Rate:")
print(cancellation_rate)

# Hotel Type
sns.countplot(x='hotel', data=df)
plt.title('Type of Hotel Booked')
plt.xlabel('Hotel Type')
plt.ylabel('Count')
plt.show()

# Meal Types
sns.countplot(x='meal', data=df)
plt.title('Meal Plan Types')
plt.xlabel('Meal Plan')
plt.ylabel('Count')
plt.show()

"""**Missing Values**(Data Cleaning)"""

df['children'] = df['children'].fillna(0)
df['agent'] = df['agent'].fillna(0)
df['company'] = df['company'].fillna(0)

"""**Data Preparing**"""

#  total guests feature
df['total_guests'] = df['adults'] + df['children'] + df['babies']

# 'is_family' feature
df['is_family'] = np.where((df['children'] > 0) | (df['babies'] > 0), 1, 0)

# Lead time buckets
def bucket_lead_time(x):
    if x < 30:
        return 'Short'
    elif 30 <= x <= 90:
        return 'Medium'
    else:
        return 'Long'

df['lead_time_bucket'] = df['lead_time'].apply(bucket_lead_time)

"""**Label Encoding**"""

label_encoders = {}
cat_cols = ['hotel', 'meal', 'market_segment', 'distribution_channel',
            'reserved_room_type', 'deposit_type', 'customer_type']

for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

    print(f"\nLabel Encoding for '{col}':")
    mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    for k, v in mapping.items():
        print(f"  {k} --> {v}")

# Encode 'lead_time_bucket'
le_bucket = LabelEncoder()
df['lead_time_bucket'] = le_bucket.fit_transform(df['lead_time_bucket'])
print("\nLabel Encoding for 'lead_time_bucket':")
bucket_mapping = dict(zip(le_bucket.classes_, le_bucket.transform(le_bucket.classes_)))
for k, v in bucket_mapping.items():
    print(f"  {k} --> {v}")

#Dropping unnecessary columns
drop_cols = ['arrival_date_year', 'arrival_date_month', 'arrival_date_week_number',
             'arrival_date_day_of_month', 'agent', 'company', 'country',
             'reservation_status', 'reservation_status_date']
df.drop(columns=drop_cols, inplace=True)

print(f"Encoded values for 'lead_time_bucket': {sorted(df['lead_time_bucket'].unique())}")
# Now find remaining object type columns automatically
remaining_object_cols = df.select_dtypes(include=['object']).columns.tolist()

if remaining_object_cols:
    print("\n\nEncoding Remaining Categorical Columns:")

    for col in remaining_object_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

        # Print the mappings
        print(f"\nLabel Encoding for '{col}':")
        mapping = dict(zip(le.classes_, le.transform(le.classes_)))
        for k, v in mapping.items():
            print(f"  {k} --> {v}")

        # Print unique encoded values
        print(f"Encoded values for '{col}': {sorted(df[col].unique())}")
else:
    print("\n\nNo remaining categorical columns to encode.")

print(df.dtypes)

for col in df.columns:
    non_numeric = df[col].apply(lambda x: isinstance(x, str)).sum()
    if non_numeric > 0:
        print(f"⚠️ Column '{col}' has {non_numeric} string values.")

print(df['reserved_room_type'].unique())
print(df['assigned_room_type'].unique())

y = df['is_canceled']
X = df.drop('is_canceled', axis=1)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Data Split Completed.\n")
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape : {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape : {y_test.shape}")

# Class Distribution Check
print("\nClass distribution in y_train:")
print(y_train.value_counts(normalize=True).rename_axis('is_canceled').reset_index(name='proportion'))

print("\nClass distribution in y_test:")
print(y_test.value_counts(normalize=True).rename_axis('is_canceled').reset_index(name='proportion'))

df.head()

X_train = X_train.fillna(X_train.median(numeric_only=True))
X_test = X_test.fillna(X_test.median(numeric_only=True))

"""**Logistic Regression**"""

# Logistic Regression Model
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train, y_train)

# Predictions
y_pred_lr = log_reg.predict(X_test)

# Evaluation
print("Logistic Regression Evaluation\n")
print("Classification Report:")
print(classification_report(y_test, y_pred_lr, digits=4))

print(f"Accuracy Score: {accuracy_score(y_test, y_pred_lr):.4f}")

"""**Random Forest**"""

# Random Forest model
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# Predictions
y_pred_rf = rf.predict(X_test)

# Evaluation
print("Random Forest Results:")
print(classification_report(y_test, y_pred_rf))
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")

from xgboost import XGBClassifier

# XGBoost model
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)

# Predictions
y_pred_xgb = xgb.predict(X_test)

# Evaluation
print("XGBoost Results:")
print(classification_report(y_test, y_pred_xgb))
print(f"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")

"""**Evaluation of all 3 Models**"""

model_results = {
    'Model': [],
    'Accuracy': [],
    'Precision': [],
    'Recall': [],
    'F1 Score': []
}

models = {
    'Logistic Regression': y_pred_lr,
    'Random Forest': y_pred_rf,
    'XGBoost': y_pred_xgb
}

for model_name, preds in models.items():
    model_results['Model'].append(model_name)
    model_results['Accuracy'].append(accuracy_score(y_test, preds))
    model_results['Precision'].append(precision_score(y_test, preds))
    model_results['Recall'].append(recall_score(y_test, preds))
    model_results['F1 Score'].append(f1_score(y_test, preds))

results_df = pd.DataFrame(model_results)
results_df

# Plot confusion matrix for best model
best_model_preds = y_pred_rf

cm = confusion_matrix(y_test, best_model_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')

"""**Feature Importance**"""

rf_importances = rf.feature_importances_
rf_features = pd.Series(rf_importances, index=X.columns)
rf_features_sorted = rf_features.sort_values(ascending=False)

plt.figure(figsize=(10,6))
rf_features_sorted.plot(kind='bar')
plt.title('Random Forest - Feature Importances')
plt.ylabel('Importance Score')
plt.xlabel('Features')
plt.tight_layout()
plt.show()

"""**Tunning Hyperparameters**"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'bootstrap': [True]
}


rf_model = RandomForestClassifier(random_state=42)


grid_search = GridSearchCV(
    estimator=rf_model,
    param_grid=param_grid,
    cv=3,                # 3-fold cross-validation
    n_jobs=-1,           # use all cores
    verbose=2,
    scoring='accuracy'
)

# Fit on training data
grid_search.fit(X_train, y_train)
print("\nBest Hyperparameters:")
print(grid_search.best_params_)
best_rf = grid_search.best_estimator_

# Evaluate best model
y_pred_best_rf = best_rf.predict(X_test)

print("\nRandom Forest (Tuned) Results:")
print(classification_report(y_test, y_pred_best_rf))
print(f"Accuracy: {accuracy_score(y_test, y_pred_best_rf):.4f}")

# Get feature importances
importances = best_rf.feature_importances_

feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Plot top 10 features
plt.figure(figsize=(10,6))
plt.barh(feature_importance_df['Feature'][:10], feature_importance_df['Importance'][:10])
plt.gca().invert_yaxis()
plt.title('Top 10 Important Features')
plt.xlabel('Importance Score')
plt.show()

feature_importance_df

"""**Predicting on testing data**"""

y_pred_final = best_rf.predict(X_test)
print("Final Model Evaluation on Test Set:")
print(classification_report(y_test, y_pred_final))
print(f"Accuracy: {accuracy_score(y_test, y_pred_final):.4f}")

results = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred_final
})

print(results.head(20))

import joblib
best_model = grid_search.best_estimator_

model_package = {
    "model": best_model,
    "best_params": grid_search.best_params_,
    "features": X_train.columns.tolist(),
    "accuracy": accuracy_score(y_test, y_pred_final)
}


joblib.dump(model_package, 'random_forest_full_model.pkl')

print("Full model and info saved successfully!")

print(X_train.columns.tolist())

# Example input
sample_input = pd.DataFrame([{
    'hotel': 1,                              # 1 = City Hotel
    'lead_time': 120,
    'stays_in_weekend_nights': 2,
    'stays_in_week_nights': 3,
    'adults': 2,
    'children': 0,
    'babies': 0,
    'meal': 2,                               # 2 = BB
    'market_segment': 1,                     # 1 = Direct
    'distribution_channel': 0,               # 0 = Direct
    'is_repeated_guest': 0,
    'previous_cancellations': 0,
    'previous_bookings_not_canceled': 0,
    'reserved_room_type': 3,
    'assigned_room_type': 3,
    'booking_changes': 0,
    'deposit_type': 0,                       # 0 = No deposit
    'days_in_waiting_list': 0,
    'customer_type': 1,                      # 1 = Transient
    'adr': 100.5,                            # average daily rate
    'required_car_parking_spaces': 0,
    'total_of_special_requests': 1,
    'total_guests': 2,
    'is_family': 1,
    'lead_time_bucket': 2                    # 2 = Long
}])

# Predict using the trained Random Forest model
prediction = rf.predict(sample_input)
print("Prediction:", "Canceled" if prediction[0] == 1 else "Not Canceled")